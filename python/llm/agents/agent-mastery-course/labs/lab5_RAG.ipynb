{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
        "    </p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "Rc9Ohodqa_gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Arize Agent Mastry Course: RAG & Agentic RAG**"
      ],
      "metadata": {
        "id": "V1HXBFLtbEgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous lab, we explored tools in depth and saw how enhancing them can strengthen our agents‚Äô responses. Another powerful way to improve performance is by using **Retrieval-Augmented Generation (RAG)** to give the agent access to specific data sources. In this lab, the agent will retrieve relevant documents from a vector database and use that information to answer queries. We‚Äôll continue building on the agent we created earlier."
      ],
      "metadata": {
        "id": "hmf1YyMqbYcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "U1A2VnzycKYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PieRuLGf7ugU"
      },
      "outputs": [],
      "source": [
        "!pip install -qqqqqqqq arize-otel agno openai openinference-instrumentation-agno openinference-instrumentation-openai httpx chromadb sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"ARIZE_SPACE_ID\"] = userdata.get(\"ARIZE_SPACE_ID\") or getpass(\"üîë Enter your Arize Space ID: \")\n",
        "\n",
        "os.environ[\"ARIZE_API_KEY\"] = userdata.get(\"ARIZE_API_KEY\") or getpass(\"üîë Enter your Arize API Key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\") or getpass(\"üîë Enter your OpenAI API Key: \")\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\") or getpass(\"üîë Enter your Tavily API Key: \")"
      ],
      "metadata": {
        "id": "mfgANTGsqO6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from arize.otel import register\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "from openinference.instrumentation.agno import AgnoInstrumentor\n",
        "\n",
        "model_id = \"travel-agent-demo\"\n",
        "tracer_provider = register(\n",
        "    space_id=os.getenv(\"ARIZE_SPACE_ID\"),\n",
        "    api_key=os.getenv(\"ARIZE_API_KEY\"),\n",
        "    project_name=model_id,\n",
        "    set_global_tracer_provider=True,\n",
        "    log_to_console=True,\n",
        "    endpoint=\"https://otlp.ca-central-1a.arize.com/v1/traces\",\n",
        "    transport=Transport.HTTP\n",
        ")\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "AgnoInstrumentor().instrument(tracer_provider=tracer_provider)"
      ],
      "metadata": {
        "id": "3PZNGrszQJ-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Tools"
      ],
      "metadata": {
        "id": "Ogbl-o3IQ90I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tool implementation for `essential_info` and `budget_basics` is unchanged."
      ],
      "metadata": {
        "id": "dPaFROIZcPeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper functions for tools ---\n",
        "import httpx\n",
        "from opentelemetry import trace\n",
        "\n",
        "tracer = trace.get_tracer(__name__)\n",
        "\n",
        "@tracer.chain(name=\"search-api\")\n",
        "def _search_api(query: str) -> str | None:\n",
        "    \"\"\"Try Tavily search first, fall back to None.\"\"\"\n",
        "    tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "    if not tavily_key:\n",
        "        return None\n",
        "    try:\n",
        "        resp = httpx.post(\n",
        "            \"https://api.tavily.com/search\",\n",
        "            json={\n",
        "                \"api_key\": tavily_key,\n",
        "                \"query\": query,\n",
        "                \"max_results\": 3,\n",
        "                \"search_depth\": \"basic\",\n",
        "                \"include_answer\": True,\n",
        "            },\n",
        "            timeout=8,\n",
        "        )\n",
        "        data = resp.json()\n",
        "        answer = data.get(\"answer\") or \"\"\n",
        "        snippets = [r.get(\"content\", \"\") for r in data.get(\"results\", [])]\n",
        "        combined = \" \".join([answer] + snippets).strip()\n",
        "        return combined[:400] if combined else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _compact(text: str, limit: int = 200) -> str:\n",
        "    \"\"\"Compact text for cleaner outputs.\"\"\"\n",
        "    cleaned = \" \".join(text.split())\n",
        "    return cleaned if len(cleaned) <= limit else cleaned[:limit].rsplit(\" \", 1)[0]\n"
      ],
      "metadata": {
        "id": "zrAqXWtxQLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APIs for Essential Info Tool\n",
        "import httpx\n",
        "from urllib.parse import quote\n",
        "from typing import Optional\n",
        "\n",
        "@tracer.chain(name=\"wiki-summary-api\")\n",
        "def _wiki_summary(dest: str) -> str:\n",
        "    if not dest:\n",
        "        return \"\"\n",
        "    encoded_dest = quote(dest)\n",
        "\n",
        "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{encoded_dest}\"\n",
        "    HEADERS = { 'User-Agent': 'MyArizeApp/1.0 (ExampleContac@example.com)'}\n",
        "\n",
        "    try:\n",
        "        r = httpx.get(url, headers = HEADERS, timeout=5)\n",
        "        r.raise_for_status()\n",
        "\n",
        "        data = r.json().get(\"extract\")\n",
        "        return data if data else \"\"\n",
        "\n",
        "    except httpx.HTTPStatusError as e:\n",
        "        if e.response.status_code == 404:\n",
        "            return \"\"\n",
        "        return \"\"\n",
        "    except httpx.RequestError as e:\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        return \"\"\n",
        "\n",
        "@tracer.chain(name=\"weather-api\")\n",
        "def _weather(dest):\n",
        "    g = httpx.get(f\"https://geocoding-api.open-meteo.com/v1/search?name={dest}\")\n",
        "    if g.status_code != 200 or not g.json().get(\"results\"):\n",
        "        return \"\"\n",
        "    lat, lon = g.json()[\"results\"][0][\"latitude\"], g.json()[\"results\"][0][\"longitude\"]\n",
        "    w = httpx.get(f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\").json()\n",
        "    cw = w.get(\"current_weather\", {})\n",
        "    return f\"Weather now: {cw.get('temperature')}¬∞C, wind {cw.get('windspeed')} km/h.\""
      ],
      "metadata": {
        "id": "JAXZhxYFQNBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agno.tools import tool\n",
        "\n",
        "@tool\n",
        "def essential_info(destination: str) -> str:\n",
        "    \"\"\"Get essential info (summary and weather) using APIs\"\"\"\n",
        "    parts = []\n",
        "    wiki = _wiki_summary(destination)\n",
        "    if wiki: parts.append(wiki)\n",
        "    weather = _weather(destination)\n",
        "    if weather: parts.append(weather)\n",
        "    return f\"{destination} essentials:\\n\" + \"\\n\".join(parts)\n",
        "\n",
        "@tool\n",
        "def budget_basics(destination: str, duration: str) -> str:\n",
        "    \"\"\"Summarize travel cost categories.\"\"\"\n",
        "    q = f\"{destination} travel budget average daily costs {duration}\"\n",
        "    s = _search_api(q)\n",
        "    if s:\n",
        "        return f\"{destination} budget ({duration}): {_compact(s)}\"\n",
        "    return f\"Budget for {duration} in {destination} depends on lodging, meals, transport, and attractions.\""
      ],
      "metadata": {
        "id": "b99WNnmEXfgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create RAG System for Local Flavor Tool"
      ],
      "metadata": {
        "id": "uNkrWM89RAA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it‚Äôs time to make our `local_flavor` tool even smarter by giving it access to a rich database of travel destination insights. We‚Äôll use ChromaDB as the vector database and a Sentence Transformer model to generate embeddings that allow the tool to find and retrieve the most relevant information."
      ],
      "metadata": {
        "id": "STcaFYqJcZPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create collection for local guides\n",
        "collection = chroma_client.create_collection(\n",
        "    name=\"local_guides\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "print(\"‚úÖ RAG system initialized with ChromaDB and sentence-transformers\")"
      ],
      "metadata": {
        "id": "xn0R4FHFUpG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and upload `local_flavor.json` file provided to you here:"
      ],
      "metadata": {
        "id": "HKJOkyQ1REek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "guide = files.upload()"
      ],
      "metadata": {
        "id": "abGYubKMTdO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_and_index_guides():\n",
        "\n",
        "    with open('local_guides.json', 'r') as f:\n",
        "      guides = json.load(f)\n",
        "\n",
        "    # Prepare data for ChromaDB\n",
        "    documents = []\n",
        "    metadatas = []\n",
        "    ids = []\n",
        "\n",
        "    for i, guide in enumerate(guides):\n",
        "        # Create a rich text representation for embedding\n",
        "        text = f\"City: {guide['city']}. Interests: {', '.join(guide['interests'])}. Experience: {guide['description']}\"\n",
        "\n",
        "        documents.append(text)\n",
        "        metadatas.append({\n",
        "          \"city\": guide[\"city\"],\n",
        "          \"interests\": \", \".join(guide[\"interests\"]),  # ‚úÖ make it a string\n",
        "          \"source\": guide[\"source\"],\n",
        "          \"description\": guide[\"description\"]\n",
        "        })\n",
        "        ids.append(f\"guide_{i}\")\n",
        "\n",
        "    # Add to ChromaDB collection\n",
        "    collection.add(\n",
        "        documents=documents,\n",
        "        metadatas=metadatas,\n",
        "        ids=ids\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Indexed {len(documents)} experiences in vector database\")\n",
        "    return len(documents)\n",
        "\n",
        "# Load the data\n",
        "num_guides = load_and_index_guides()\n"
      ],
      "metadata": {
        "id": "IPykxefuRKbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from openinference.semconv.trace import SpanAttributes, DocumentAttributes\n",
        "\n",
        "# Initialize embedding model (same one you used for indexing)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "@tool\n",
        "def local_flavor(destination: str, interests: str = \"local culture\") -> str:\n",
        "    \"\"\"Suggest authentic local experiences using vector retrieval from Chroma.\"\"\"\n",
        "    with tracer.start_as_current_span(name=\"RAG\", attributes={SpanAttributes.OPENINFERENCE_SPAN_KIND: \"retriever\"}) as span:\n",
        "      # Construct the query text\n",
        "      query_text = f\"{destination} {interests} authentic experiences\"\n",
        "      span.set_attribute(SpanAttributes.INPUT_VALUE, query_text)\n",
        "\n",
        "      # Embed the query\n",
        "      query_embedding = embedding_model.encode([query_text])\n",
        "\n",
        "      # Search in Chroma collection\n",
        "      results = collection.query(\n",
        "          query_embeddings=query_embedding,\n",
        "          n_results=3  # how many guides to retrieve\n",
        "      )\n",
        "\n",
        "      # If nothing found\n",
        "      if not results or not results.get(\"documents\"):\n",
        "          return f\"Explore {destination}'s unique {interests} through markets, neighborhoods, and local eateries.\"\n",
        "\n",
        "      # Extract retrieved guides\n",
        "      retrieved_docs = results[\"documents\"][0]\n",
        "      retrieved_meta = results[\"metadatas\"][0]\n",
        "      for i, doc in enumerate(retrieved_docs):\n",
        "        span.set_attribute(f\"retrieval.documents.{i}.document.id\", f\"doc_{i}\")\n",
        "        span.set_attribute(f\"retrieval.documents.{i}.document.content\", doc)\n",
        "\n",
        "      # Format a nice summary\n",
        "      suggestions = []\n",
        "      for doc, meta in zip(retrieved_docs, retrieved_meta):\n",
        "          suggestion = f\"üìç **{meta['city']}** ‚Äî {meta['description']} (Interests: {meta['interests']})\"\n",
        "          suggestions.append(suggestion)\n",
        "\n",
        "      # Combine into one readable response\n",
        "      response = f\"Here are some authentic {interests} experiences near {destination}:\\n\\n\" + \"\\n\\n\".join(suggestions)\n",
        "      span.set_attribute(SpanAttributes.OUTPUT_VALUE, response)\n",
        "\n",
        "      return response\n"
      ],
      "metadata": {
        "id": "vdNq15_QXbDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Agent"
      ],
      "metadata": {
        "id": "L5NL30n6RJN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agno.agent import Agent\n",
        "from agno.models.openai import OpenAIChat\n",
        "\n",
        "# --- Main Agent ---\n",
        "trip_agent = Agent(\n",
        "    name=\"TripPlanner\",\n",
        "    role=\"AI Travel Assistant\",\n",
        "    model=OpenAIChat(id=\"gpt-4.1\"),\n",
        "    instructions=(\n",
        "        \"You are a friendly and knowledgeable travel planner. \"\n",
        "        \"Combine multiple tools to create a trip plan including essentials, budget, and local flavor. \"\n",
        "        \"Keep the tone natural, clear, and under 1000 words.\"\n",
        "    ),\n",
        "    markdown=True,\n",
        "    tools=[essential_info, budget_basics, local_flavor],\n",
        ")"
      ],
      "metadata": {
        "id": "gOPVdh4dQOjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run the Agent ---\n",
        "destination = \"Dubai\"\n",
        "duration = \"5 days\"\n",
        "interests = \"history, wellness\"\n",
        "\n",
        "query = f\"\"\"\n",
        "Plan a {duration} trip to {destination}.\n",
        "Focus on {interests}.\n",
        "Include essential info, budget breakdown, and local experiences.\n",
        "\"\"\"\n",
        "trip_agent.print_response(\n",
        "  query,\n",
        "  stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "8Bb5fyY0QPuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if we inspect the trace, we can see that the `local_flavor` tool retrieves documents from the vector database. These retrieved documents are then used to generate tailored local recommendations."
      ],
      "metadata": {
        "id": "s-FicGzGfrG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![RAG](https://storage.googleapis.com/arize-phoenix-assets/assets/images/arize-course-rag-lab.png)"
      ],
      "metadata": {
        "id": "fVBVn08NfpO3"
      }
    }
  ]
}